# 常见问题

# 雅意大模型相关

### Q1： 雅意大模型有哪些核心能力？

A1：雅意具备以下核心能力：文本分类、复杂场景信息抽取、摘要总结、情感计算、多语种机器翻译、多模态内容生成、知识库问答。

多模态内容生成：根据输入的上下文和提示自动生成文本段落、代码或图片，包括新闻、评论、诗歌、代码建议、广告文案等。

自然语言理解：理解和解释自然语言文本。它可以执行文本分类、情感分析、命名实体识别、关键词提取等任务，帮助识别文本中的信息和语义。

对话生成：构建智能对话系统，使其能够与用户进行自然而流畅的对话。适用于聊天机器人、虚拟助手、客户支持等应用。

翻译：实时翻译，将文本从一种语言翻译成另一种语言。

内容摘要：生成文本的摘要，将长篇文章或文档精简成简明扼要的版本，帮助用户快速了解文本的要点。

知识库问答：接入自有知识库，实现知识库问答。支持问题推荐、摘要总结、多轮对话、信息定位、联网问答等。

### Q2： 雅意大模型的服务形式有哪些？

A2： 服务形式主要有以下 4 种：

1）通过 YAYIChat  和 YAYI File 等应用使用大模型服务

2）通过开放平台开通调用雅意大模型 API 服务

3）私有化部署：包含云端部署和本地部署

4）雅意大模型一体机

### Q3： 雅意大模型产品应用于哪些领域？

A3： 雅意大模型可应用于媒体，舆情，金融，治理、教育、政务、电商、广告等众多领域，也支持针对其他垂直场景训练专属领域大模型。

### Q4： 模型的更新迭代周期是多久？是否有持续的优化计划？

A4： 迭代周期为 1-2 个月。有持续优化计划。

### Q5： 雅意 7B 和雅意 13B 主要不同点？

A5： 主要不同点如下：

1）模型规模：7B 模型拥有 70 亿个参数，而 13B 模型拥有 130 亿个参数。较大的参数规模使得 13B 模型具有更强大的语言理解能力、逻辑推理能力；

2）生成能力：由于参数更多，13B 模型在生成文本方面可能会更加流畅、准确，并且能够产生更多细节，使得对话更加自然；

3）上下文长度：7B 模型的上下文长度限制为 2048 个标记，而 13B 模型的上下文长度限制为 4096 个标记。较长的上下文长度使得 13B 模型能够更好地理解和处理更长的文本；

4）训练数据：13B 模型相较于 7B 模型有更多的训练数据。大量的训练数据能够帮助模型更好地学习不同领域的知识和语言规则；

5）资源消耗：由于规模更大，运行 13B 模型需要更多的计算资源和时间。相对而言，7B 模型对计算资源的要求较低一些。

### Q6： 雅意大模型的参数规模是多少？

A6： 雅意提供 7B/13B/30B/70B，以及更大规模参数的模型，从而适应不同应用场景、算力条件。

### Q7： 雅意大模型和其他大模型的区别？

A7： 雅意大模型更加聚焦领域任务，以解决行业应用问题为目标，面向人和应用系统提供对话式、抽取式的大模型应用方式。同时，雅意大模型在设计之初就非常重视模型自身的安全，尤其是模型输出内容的可信性、可靠性和安全性，依托于在安全行业积累的大量指令数据，雅意大模型在涉及国家安全、政治意识等方面，能够达到较好的效果。各行业可以基于雅意大模型，建设安全可靠的专属领域大模型应用。

### Q8： 要构建行业大模型，模型训练/微调的流程和采用的方法是什么？

A8： 构建行业大模型首先需要进行大量通用文本数据+行业数据的预训练。推荐数据量在 1.2-2.5 万亿 tokens。其次，需要在预训练模型的基础上基于行业的垂直任务，构建大量的指令微调数据。然后进行指令微调的训练。最后，要提升更好的一个模型输出效果（达到人的满意度），需要再进行 RLHF 的训练。

### Q9： 客户如何基于自有数据进行模型训练？此过程中需要掌握哪些技能和知识？

A9： 若用户有训练需求，目前有三种解决方案：

1）用户将数据提交给我们的算法团队，我们训练好的模型支持通过接口或雅意一体机的形式提供给客户使用

2）通过雅意一体机（旗舰版）内置的模型训练平台，完成数据上传、标注、模型训练和模型部署。

3）用户本地化部署雅意训练模型，需要有自己的算法团队去做大模型训练。

需要掌握的技能和知识：Python，大模型常用的技术参数，大模型效果测试技术

# 雅意一体机相关

### Q10： 雅意一体机的硬件配置是什么样的？

A10：雅意一体机有 4 个版本，不同版本对应不同的硬件配置。其中标准版主要面向轻量客户，提供 1 路雅意服务；通用版提供 3 路服务；高级版和旗舰版分别提供 6 路和 20 路服务。此外，旗舰版不仅能够提供雅意服务，同时能够进行模型的迭代训练，机构和企业自己就能训练专属大模型。

|            | 标准版                                                                       | 通用版                                                                      | 高级版                                                                           | 旗舰版                                                                           |
| ---------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |
| 外观       | 塔式                                                                         | 塔式                                                                        | 4U 机架                                                                          | 4U/6U 机架                                                                       |
| CPU        | 1 颗  Intel Xeon Gold 5317 Processor 3.00GHz 18 MB 12C 24T 150W 3UPI 2933MHz | 2 颗  Intel Xeon Gold 5317 Processor 3.00GHz 18MB 12C 24T 150W 3UPI 2933MHz | 2 颗  Intel Xeon Platinum 8358P Processor 2.60GHz 48MB 32C 64T 240W 3UPI 3200MHz | 2 颗  Intel Xeon Platinum 8358P Processor 2.60GHz 48MB 32C 64T 240W 3UPI 3200MHz |
| 内存       | 2 条  64GB DDR4 ECC                                                          | 4 条  64GB DDR4 ECC                                                         | 4 条  64GB DDR4 ECC                                                              | 16 条  64GB DDR4 ECC                                                             |
| 硬盘       | 1 块  SSD 960GB SATA 6Gbps 2.5 寸   读取型  <1DWPD                           | 1 块  SSD 960GB SATA 6Gbps 2.5 寸   读取型  <1DWPD                          | 2 块  SSD 1.92TB SATA 6Gbps 2.5 寸   读取型  <1DWPD                              | 4 块  SSD 3.84TB SATA 6Gbps 2.5 寸读取型  <1DWPD                                 |
| GPU        | 2 块  GeForce RTX 4090 24GB                                                  | 4 块  GeForce RTX 5000 Ada 32GB                                             | 8 块  NVIDIA L40 48GB                                                            | 8 块  NVIDIA A100/A800 80G                                                       |
| 电源       | 1 套  GPU 专用 2000W  无冗余                                                 | 1 套  GPU 专用 2000W CRPS 1+1 冗余电源                                      | 1 套  GPU 专用 2000W CRPS 1+1 冗余电源                                           | 1 套  GPU 专用 4500W CRPS 1+1 冗余电源                                           |
| 上下文长度 | 4k                                                                           | 8k                                                                          | 8k                                                                               | 8k                                                                               |
| 模型参数   | 7B/13B 可选                                                                  | 7B/13B 可选                                                                 | 7B/13B 可选                                                                      | 7B/13B/30B/70B 可选                                                              |

### Q11： 设备是否支持无缝扩展 GPU 和其他计算资源？

A11： 通用版设备的部分批次支持扩展  GPU，所有规格都预留有扩增内存、外存（机械硬盘、固态硬盘）的槽位。需要注意的是，自行拆解一体机设备将失去硬件设备的保修。此外，由于  GPU  设备对电源要求较高，扩展  GPU  可能需要更换更大功率的电源，相应的可能涉及对电路的改造（高功率电源设备通常使用  16A  插头）。

### Q12： 大模型是否支持全部国产化硬件配置？

A12： 除 GPU 外，其余建议保持原有型号，目前不同型号的设备都需要进行适配才能稳定运行，暂不支持替换，若替换其他配置可能存在稳定性问题，可以考虑采购雅意一体机。

### Q13： 数据预处理和加载的优化策略是？

A13： 分为硬件和软件层面。硬件层面采用读取型存储设备，配合高速内存硬件实现快速的数据处理和加载。软件层面利用了模型加速框架进行加载和推理的优化加速。

### Q14： 数据传输的带宽如何？

A14： 不同批次略有差异，典型的是 1Gbps，部分批次会配备 10Gbps 的网络接口。

### Q15： 雅意一体机模型训练服务（初始 2000k tokens）和训练语料增购两者关系是什么？

A15： 这两者之间的关系是：初始配额的 2000k tokens 是指在已有的训练数据上，使用 200 万个标记进行模型训练，而训练语料的增购则是为了进一步丰富训练数据，以提高模型的表达能力和语言理解能力。增购的训练语料可以是更多的文本数据，可以来自不同领域、不同风格的文本，以及各种多样化的语言用途。

通过增购训练语料，可以提供更多的样本和场景给模型进行学习，增加训练数据量，进而有助于模型更好地理解和生成文本。同时，更丰富的训练数据也能够提升模型的泛化能力，使其在不熟悉的领域或场景下也能有更好的表现。

### Q16： 雅意一体机训练咨询服务，是否只针对雅意旗舰版？

A16： 是的，只有旗舰版才支持训练和推理，覆盖数据标注、模型训练、推理预测的全流程开发。

### Q17： 领域知识体系、领域知识库是怎样搭建形成的？

A17： 私域数据接入采用按库定价的方式，单个知识库的数据量不超过硬件设备存储空间即可。但要求单个知识库的数据表结构不超过 2 种（即：允许单个知识库接入多张结构相同的数据表）。私域知识库接入为定制服务，暂不支持一键导入。正在推出的文档知识库支持 doc/docx/pdf/txt 格式文件上传。

### Q18： 雅意一体机多个实例就是多个账号意思吗？

A18：1 个实例指的是大模型的 1 路并发，即同一时刻可有 1 个用户使用大模型推理能力。

### Q19： 雅意大模型一体机支持的并发数？ 

A19： 实例=路，目前技术攻克，所以默认 1 实例也就是 1 路可以部署 3.5 个并发，13b 无标准版部署，对应通用版 3 路，高级版 6 路，旗舰版 14 路。

### Q20： 模型训练服务的费用是按照时间还是数据量计费的？

A20： 按照训练所需的数据量收费。如果需要在本地提供训练服务，那么需要同时增加技术人员驻场费用，具体收费方案请咨询销售。

### Q21： 雅意一体机硬件费用的计费明细是什么？是否有一次性总价，还是根据各项内容分开计费？

A21： 硬件费用分为标准的一次性总价和增值服务，不涉及分项计费。

### Q22： 雅意一体机标准版、通用版、高级版、旗舰版增值服务的维保服务价格不同主要影响因素是什么?

A22： 不同规格设备维保成本不同，增值服务涉及的软件维护成本也不同。

# 数据安全相关

### Q23： 客户数据的存储策略和地理位置？数据是否在数据中心之外被复制或传输？

A23： 客户数据通过被保护的数据存储域提供存储服务，相应数据库进行了严格的认证约束和网络访问约束。地理位置为境内，具体位置不予透露。数据仅限在数据中心内被访问。

### Q24： 雅意大模型是基于什么基础模型训练的？

A24： 雅意大模型尝试过很多基础预训练模型，目前开源的版本是基于 BLOOM 的版本。同时，公司正在重新设计大模型架构，并依托 DIOS 认知与决策智能平台的海量数据，以及在媒体、安全、金融等行业积累的数亿万级高质量数据，开展基础模型和行业模型的训练工作。

### Q25： 垂直领域大模型训练的路径、周期，所需的数据和资源，如何落地？

A24： 训练路径：一种方式是将 SFT 数据提供给闻歌，进行训练，数据会出域。另一种方式是采购雅意大模型推训一体机，可以做到 SFT 数据不出域进行训练。

训练周期：一般一周左右。根据数据量不同，硬件配置不同，训练时间不同。

所需数据：提升领域能力以制作和训练领域垂直任务的 SFT 数据为主，需要人工介入制作高质量的 SFT 数据。

所需资源：算力、数据、专业人员。

### Q26： 大模型训练/微调数据质量要求，处理后的高质量数据是什么样的？最好能够有样例数据。

A26： 微调数据由 Instruction，input，output 三部分组成。

instruction：这里写指令，即需要 AI 完成什么任务。指令需要能清晰的表达出完成什么任务。指令的表达方式可以多样化，不限于一种写法。指令中可以描写对输出结果格式的要求（注意，如果写了格式要求，在 output 中写的内容就需要是指令中要求的格式）。

input：这里写输入的内容，通常是上下文。比如抽取任务中，这里写待抽取的原始文档；问答任务中，这里写答案来源的背景知识。风格撰写的任务中，这里可以写对应该风格的一段示例；某些特殊的任务 input 可以为空。

output：这里写期望模型输出的结果。在期望的输出结果中，可以加入思维链的数据。即描述出为什么会得到这个结果，得到这个结果的推理过程用自然语言描述出来。结果中还需要包含格式，如换行符、制表符、json 格式、markdown 格式等。

样例数据可参考 hugging face 上我们开源的数据。

### Q27： 大模型的训练数据集是如何获得的？是否可以给客户演示我们的训练数据集样例？

A27： 训练数据集是我们自己处理和制作的，数据样例在 hugging face 上我们有开源的。

# 雅意  Maas  平台相关

### Q28.  用户在哪里反馈问题?

A28： 在雅意平台右下角，点击圆型“问题建议”按钮，跳转到反馈页面，用户可以在页面新建任务，运营人员会根据用户反馈问题进行答复。

### Q29.  账号使用期限是多久?

A29： 雅意平台目前在内测阶段，所有账号没有使用期限限制，但是用户免费获赠的 28 元额度用完后，需要自主充值完成才可以继续使用。

### Q30： 开通雅意试用账号，可以把数据上传进行训练吗?

A30： 雅意平台目前仅用于体验大模型，不支持训练，后续将推出大模型训练平台，届时会支持用户上传自有数据，进行模型训练。

若用户有训练需求，目前有三种解决方案：

1.  用户将数据提交给我们的算法团队，我们训练好的模型支持通过接口或雅意一体机的形式提供给客户使用；

2.  采购雅意一体机旗舰版，支持用户自行标注数据做训练；

3.  用户本地化部署雅意训练模型，需要有自己的算法团队去做大模型训练。

### Q31.  是否有详细的 APl 文档？能共享同事或者未购买客户吗？

A31： 登录[++YAYIChat++](https：//localhost/)后，会自动开通雅意大模型服务获取 appkey 和 appsecret，可按照接口文档调用大模型接口。不可分享给同事或其他未购买客户。

# 部署相关

### Q32： 私有化部署需要哪种 GPU 服务器以及具体数量？请提供预计的硬件参数和成本。

A32： 雅意部署分为训练用及推理用两种

训练用配置（参考价 150 万）

CPU：2\*32 核  (intel) Intel Xeon Gold 6338

内存：1T 以上

GPU：8 × NVIDIA Tesla A100 80G

固态（系统盘）：2T 以上

数据盘：6×8T7200 转及其转以上

raid 卡支持 raid 1、raid5、raid 10

至少 3 年原厂维保

推理用配置  （参考价 25 万）

CPU：2\*32 核(intel) Intel Xeon Gold 6338

内存：512G 以上

GPU：8 × NVIDIA 5000 Ada 32G

固态（系统盘）：1T 以上

数据盘：4×8T7200 转及其转以上

raid 卡支持 raid1、raid 5、raid 10

至少 3 年原厂维保

### Q33： 可以达到的模型推理速度、QPS 以及并发量是多少？

A33： 在开放平台提供的 AISaaS 服务目前的 QPS 约为 20，持续扩增中。实例=路，目前技术攻克，所以默认 1 实例也就是 1 路可以部署 3.5 个并发  13b 无标准版部署，对应通用版 3 路，高级版 6 路，旗舰版 14 路。

### Q34： 新版本的模型更新是否免费提供？是否有额外的升级服务?

A34： 收费，支持离线和联网升级，自购买日起一年内（具体以销售合同为准）可申请免费升级。后续升级服务按次收费，具体以销售定价为准。
